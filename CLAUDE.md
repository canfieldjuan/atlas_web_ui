# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

---

## ğŸ¯ PROJECT VISION (Read First!)

**Atlas is NOT just a home assistant.** It's an extensible AI "Brain" designed to grow from home automation into a comprehensive intelligent system.

### The Big Picture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ATLAS BRAIN                               â”‚
â”‚              (Cloud/Server - Central Intelligence)               â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚     LLM     â”‚  â”‚     STT     â”‚  â”‚     TTS     â”‚   AI Models  â”‚
â”‚  â”‚  (Reasoning)â”‚  â”‚   (Speech)  â”‚  â”‚   (Voice)   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚              Unified Voice Interface             â”‚            â”‚
â”‚  â”‚    "Hey Atlas" â†’ STT â†’ Router â†’ Action/LLM â†’ TTS â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚           PostgreSQL (Persistence)              â”‚            â”‚
â”‚  â”‚   Sessions | Conversations | Users | State      â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CENTRAL HUB                                 â”‚
â”‚                    (Jetson Nano)                                 â”‚
â”‚         Local processing, device coordination                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼               â–¼               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Node 1  â”‚   â”‚  Node 2  â”‚   â”‚  Node N  â”‚
        â”‚ (Jetson) â”‚   â”‚ (Jetson) â”‚   â”‚ (Jetson) â”‚
        â”‚ Camera   â”‚   â”‚ Sensors  â”‚   â”‚ Display  â”‚
        â”‚ Mic/Spk  â”‚   â”‚ Motion   â”‚   â”‚ Control  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Current Capabilities (Implemented)
- âœ… Voice-activated device control ("Hey Atlas, turn off the TV")
- âœ… Natural language intent parsing
- âœ… Home Assistant integration (WebSocket real-time state, media players)
- âœ… LLM for conversations and reasoning
- âœ… STT/TTS for voice interface
- âœ… PostgreSQL for conversation persistence
- âœ… Directus CRM â€” single source of truth for customer/contact data
- âœ… CRM MCP server (9 tools)
- âœ… Email MCP server (8 tools, provider-agnostic)

### Future Capabilities (Planned)
- ğŸ”² Unified always-on voice interface (wake word "Hey Atlas")
- ğŸ”² Smart routing: device commands vs conversation vs queries
- ğŸ”² Human tracking and recognition
- ğŸ”² Object detection and tracking
- ğŸ”² Distributed node architecture (Jetson Nanos)
- ğŸ”² Context-aware conversations ("dim them" â†’ knows "them" = last mentioned lights)
- ğŸ”² Calendar, reminders, proactive notifications
- ğŸ”² Multi-room audio/video coordination

### Design Principles
1. **Extensibility First**: Every component should be pluggable and replaceable
2. **Seamless Experience**: One interface for everything (chat, control, queries)
3. **Local Processing**: Prefer edge compute, cloud for heavy lifting only
4. **Persistence**: Remember conversations, learn preferences, track state
5. **Privacy**: User data stays local, no external telemetry

### Current Session Focus
When working on Atlas, always ask: "Does this fit the big picture?"
- Don't over-engineer for today, but don't block tomorrow
- Keep interfaces clean for future node distribution
- Maintain conversation context across interactions

---

## Project Overview

Atlas is a centralized AI "Brain" server and extensible automation platform. It provides:
- **AI Services**: Text, vision, and speech-to-text inference via REST API
- **Device Control**: Extensible capability system for IoT devices, home automation
- **Intent Dispatch**: Natural language commands to device actions via LLM
- **Voice Interface**: Wake word activated, seamless chat + control

## Build and Run Commands

### Local Development (Recommended for fast iteration)

```bash
# Activate virtual environment
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run with hot reload on port 8001
# Note: WebSocket ping settings prevent timeout during voice streaming
uvicorn atlas_brain.main:app --host 0.0.0.0 --port 8001 --reload --ws-ping-interval 60 --ws-ping-timeout 120
```

### ASR Server (Required for Voice Pipeline)

The ASR server provides speech-to-text for the voice pipeline. It runs separately from the main Atlas server.

```bash
# Install ASR dependencies (first time only)
pip install -r requirements.asr.txt

# Start ASR server on GPU 0, port 8081
python asr_server.py --model nvidia/nemotron-speech-streaming-en-0.6b --port 8081 --device cuda:0
```

**Endpoints:**
- `GET /health` - Server status
- `POST /v1/asr` - Batch transcription (WAV file)
- `WS /v1/asr/stream` - Streaming transcription (PCM chunks)

**Note:** The voice pipeline expects ASR at `http://127.0.0.1:8081`. Configure via `ATLAS_VOICE_ASR_URL` in `.env`.

### LLM Models (Ollama)

**Local LLM**: `qwen3:14b` (~10GB VRAM) -- conversation, reminders, calendar, intent classification.

**Cloud LLM**: `minimax-m2:cloud` (Ollama cloud relay) -- business workflows (booking, email, security escalation). Routed via `llm_router.py`.

```bash
# Pull local model
ollama pull qwen3:14b

# Pull cloud model
ollama pull minimax-m2:cloud

# Test
ollama run qwen3:14b "Hello"
```

### Docker (Production)

```bash
# Build and start the server (requires NVIDIA Container Toolkit)
docker compose up --build -d

# Restart after code changes (volumes mount atlas_brain/, so rebuild not always needed)
docker compose restart

# View logs
docker compose logs -f brain

# Stop the server
docker compose down
```

## Testing Endpoints

```bash
# Health check
curl http://127.0.0.1:8000/api/v1/ping

# Detailed health with service status
curl http://127.0.0.1:8000/api/v1/health

# Text query
curl -X POST http://127.0.0.1:8000/api/v1/query/text \
  -H "Content-Type: application/json" \
  -d '{"query_text": "What is 2+2?"}'

# Vision query (image + optional prompt)
curl -X POST http://127.0.0.1:8000/api/v1/query/vision \
  -F "image_file=@image.jpg" \
  -F "prompt_text=What is in this image?"

# Audio transcription
curl -X POST http://127.0.0.1:8000/api/v1/query/audio \
  -F "audio_file=@audio.wav"

# List registered devices
curl http://127.0.0.1:8000/api/v1/devices/

# Execute device action
curl -X POST http://127.0.0.1:8000/api/v1/devices/{device_id}/action \
  -H "Content-Type: application/json" \
  -d '{"action": "turn_on"}'

# Natural language device control
curl -X POST http://127.0.0.1:8000/api/v1/devices/intent \
  -H "Content-Type: application/json" \
  -d '{"query": "turn on the living room lights"}'
```

## Architecture

```
atlas_brain/
â”œâ”€â”€ main.py                      # FastAPI app with lifespan management
â”œâ”€â”€ config.py                    # Pydantic Settings for configuration
â”‚
â”œâ”€â”€ api/                         # API layer (routing only)
â”‚   â”œâ”€â”€ dependencies.py          # FastAPI Depends (inject services)
â”‚   â”œâ”€â”€ health.py                # /ping, /health
â”‚   â”œâ”€â”€ query/                   # AI inference endpoints
â”‚   â”‚   â”œâ”€â”€ text.py              # POST /query/text
â”‚   â”‚   â”œâ”€â”€ audio.py             # POST /query/audio, WS /ws/query/audio
â”‚   â”‚   â””â”€â”€ vision.py            # POST /query/vision
â”‚   â””â”€â”€ models/                  # Model management
â”‚       â””â”€â”€ management.py        # GET/POST /models/stt, /models/llm
â”‚   â””â”€â”€ devices/                 # Device control
â”‚       â””â”€â”€ control.py           # /devices/*, /devices/intent
â”‚
â”œâ”€â”€ schemas/                     # Pydantic request/response models
â”‚   â””â”€â”€ query.py
â”‚
â”œâ”€â”€ services/                    # AI model services
â”‚   â”œâ”€â”€ protocols.py             # LLMService protocol
â”‚   â”œâ”€â”€ base.py                  # BaseModelService with shared utilities
â”‚   â”œâ”€â”€ registry.py              # ServiceRegistry for hot-swapping (LLM)
â”‚   â”œâ”€â”€ crm_provider.py          # CRM: DirectusCRMProvider + DatabaseCRMProvider
â”‚   â”œâ”€â”€ email_provider.py        # Email: GmailEmailProvider + ResendEmailProvider
â”‚   â””â”€â”€ stt/
â”‚       â””â”€â”€ nemotron.py          # @register_stt("nemotron")
â”‚
â””â”€â”€ capabilities/                # Device/integration system
    â”œâ”€â”€ protocols.py             # Capability, CapabilityState, ActionResult
    â”œâ”€â”€ registry.py              # CapabilityRegistry
    â”œâ”€â”€ actions.py               # ActionDispatcher, Intent
    â”œâ”€â”€ intent_parser.py         # LLM â†’ Intent extraction
    â”œâ”€â”€ backends/                # Communication backends
    â”‚   â”œâ”€â”€ base.py              # Backend protocol
    â”‚   â”œâ”€â”€ mqtt.py              # MQTTBackend
    â”‚   â””â”€â”€ homeassistant.py     # HomeAssistantBackend
    â””â”€â”€ devices/                 # Device implementations
        â”œâ”€â”€ lights.py            # MQTTLight, HomeAssistantLight
        â””â”€â”€ switches.py          # MQTTSwitch, HomeAssistantSwitch

atlas_brain/mcp/                 # MCP servers (Claude Desktop / Cursor compatible)
â”œâ”€â”€ crm_server.py                # CRM MCP server  (9 tools, port 8056 SSE)
â””â”€â”€ email_server.py              # Email MCP server (8 tools, port 8057 SSE)
```

## Key Patterns

**Service Registry**: LLM services are managed via a registry supporting runtime hot-swapping:
```python
from atlas_brain.services import llm_registry
llm_registry.activate("ollama")  # Load a registered LLM implementation
llm_registry.deactivate()         # Unload to free resources
```

**CRM Provider**: Single source of truth for all customer/contact data:
```python
from atlas_brain.services.crm_provider import get_crm_provider
crm = get_crm_provider()                       # DirectusCRMProvider or DatabaseCRMProvider
contacts = await crm.search_contacts(phone="618-555-1234")
await crm.log_interaction(contact_id, "call", "Booked cleaning for Monday")
```

**Email Provider**: Provider-agnostic send + read (Gmail preferred, Resend fallback):
```python
from atlas_brain.services.email_provider import get_email_provider
email = get_email_provider()
await email.send(to=["alice@example.com"], subject="Estimate", body="...")
messages = await email.list_messages("is:unread newer_than:1d")
```

**Capability System**: Devices implement the Capability protocol and are registered:
```python
from atlas_brain.capabilities import capability_registry
capability_registry.register(my_light)
```

**Intent Dispatch**: Natural language â†’ structured intent â†’ device action:
```python
from atlas_brain.capabilities import action_dispatcher, intent_parser
intent = await intent_parser.parse("turn on the lights")
result = await action_dispatcher.dispatch_intent(intent)
```

## Adding New Device Types

Create in `capabilities/devices/`:
```python
from ..protocols import Capability, CapabilityType, ActionResult

class ThermostatCapability:
    capability_type = CapabilityType.THERMOSTAT
    supported_actions = ["set_temperature", "read"]

    async def execute_action(self, action, params): ...
```

## Environment Variables

```bash
# AI Models (LLM)
ATLAS_LLM_OLLAMA_MODEL=qwen3:14b
ATLAS_LLM_CLOUD_ENABLED=true
ATLAS_LLM_CLOUD_OLLAMA_MODEL=minimax-m2:cloud
ATLAS_LOAD_LLM_ON_STARTUP=true

# STT
ATLAS_STT_WHISPER_MODEL_SIZE=small.en
ATLAS_LOAD_STT_ON_STARTUP=false

# MQTT Backend (optional)
ATLAS_MQTT_ENABLED=false
ATLAS_MQTT_HOST=localhost
ATLAS_MQTT_PORT=1883

# Home Assistant Backend (optional)
ATLAS_HA_ENABLED=false
ATLAS_HA_URL=http://homeassistant.local:8123
ATLAS_HA_TOKEN=your_token

# Reminder System
ATLAS_REMINDER_ENABLED=true
ATLAS_REMINDER_DEFAULT_TIMEZONE=America/Chicago
ATLAS_REMINDER_MAX_REMINDERS_PER_USER=100

# Calendar Tool (Google Calendar)
ATLAS_TOOLS_CALENDAR_ENABLED=true
ATLAS_TOOLS_CALENDAR_CLIENT_ID=your_client_id
ATLAS_TOOLS_CALENDAR_CLIENT_SECRET=your_client_secret
ATLAS_TOOLS_CALENDAR_REFRESH_TOKEN=your_refresh_token

# Directus CRM (single source of truth for customer/contact data)
# Run `python scripts/setup_directus.py` after first `docker compose up -d directus`
# to auto-generate the token and write it to .env.local
ATLAS_DIRECTUS_ENABLED=false           # set true after running setup_directus.py
ATLAS_DIRECTUS_URL=http://localhost:8055
ATLAS_DIRECTUS_TOKEN=                  # written by setup_directus.py
ATLAS_DIRECTUS_ADMIN_EMAIL=admin@atlas.local
ATLAS_DIRECTUS_ADMIN_PASSWORD=atlas_admin_password
ATLAS_DIRECTUS_SECRET=change-me-in-production   # used by Directus container

# MCP Servers (Claude Desktop / Cursor integration)
# Default transport is stdio. Set ATLAS_MCP_TRANSPORT=sse to expose as HTTP.
ATLAS_MCP_TRANSPORT=stdio
ATLAS_MCP_CRM_PORT=8056    # CRM MCP server (SSE mode only)
ATLAS_MCP_EMAIL_PORT=8057  # Email MCP server (SSE mode only)
```

## Directus CRM Setup

Directus is the single source of truth for all customer/contact data, replacing
the previous approach of inferring customer records from appointment rows and
GraphRAG accumulation.

```bash
# 1. Start Postgres + Directus
docker compose up -d postgres directus

# 2. Wait until Directus is ready (look for "Server started at â€¦")
docker compose logs -f directus

# 3. Create API token and write to .env.local
python scripts/setup_directus.py

# 4. Re-start brain with DirectusCRMProvider active
docker compose restart brain

# Directus Admin UI (manage contacts, interactions, etc.)
open http://localhost:8055/admin
```

The `contacts` table (created by migration `035_contacts.sql`) is the CRM schema.
Until `ATLAS_DIRECTUS_ENABLED=true` + `ATLAS_DIRECTUS_TOKEN` are set, Atlas
automatically falls back to `DatabaseCRMProvider` (direct asyncpg queries against
the same `contacts` table).

## MCP Servers

Two provider-agnostic MCP servers expose the CRM and email to any MCP client
(Claude Desktop, Cursor, custom agents).

### CRM MCP Server (9 tools)
```bash
# stdio mode (Claude Desktop / Cursor)
python -m atlas_brain.mcp.crm_server

# SSE HTTP mode (port 8056)
python -m atlas_brain.mcp.crm_server --sse
```

Tools: `search_contacts`, `get_contact`, `create_contact`, `update_contact`,
`delete_contact`, `list_contacts`, `log_interaction`, `get_interactions`,
`get_contact_appointments`

### Email MCP Server (8 tools)
```bash
# stdio mode (Claude Desktop / Cursor)
python -m atlas_brain.mcp.email_server

# SSE HTTP mode (port 8057)
python -m atlas_brain.mcp.email_server --sse
```

Tools: `send_email`, `send_estimate`, `send_proposal`, `list_inbox`,
`get_message`, `search_inbox`, `get_thread`, `list_sent_history`

**Sending**: Gmail preferred (OAuth2); falls back to Resend if Gmail is not configured.
**Reading**: Gmail only (`list_inbox`, `search_inbox`, `get_thread`).

### Claude Desktop config (`~/.claude/claude_desktop_config.json`)
```json
{
  "mcpServers": {
    "atlas-crm": {
      "command": "python",
      "args": ["-m", "atlas_brain.mcp.crm_server"],
      "cwd": "/path/to/ATLAS"
    },
    "atlas-email": {
      "command": "python",
      "args": ["-m", "atlas_brain.mcp.email_server"],
      "cwd": "/path/to/ATLAS"
    }
  }
}
```

## Environment Requirements

- NVIDIA GPU with 24GB+ VRAM (RTX 3090/4090) - single GPU setup
  - LLM (qwen3:14b): ~10GB VRAM
  - ASR (Nemotron 0.6B): ~2GB VRAM
- NVIDIA Container Toolkit installed on host (see `install_nvidia_toolkit.sh`)
- Docker and Docker Compose
- Ollama for LLM serving
